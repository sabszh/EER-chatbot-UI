{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from data_chunking import datachunk\n",
    "from langchain_huggingface import HuggingFaceEmbeddings, HuggingFaceEndpoint as HuggingFaceHub\n",
    "from langchain_community.vectorstores.pinecone import Pinecone\n",
    "from pinecone import Pinecone as pc\n",
    "from pinecone import ServerlessSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datachunk(transcripts_folder, pdf_folder):\n",
    "    csv_files = [file for file in os.listdir(transcripts_folder) if file.endswith('.csv')]\n",
    "    pdf_files = [file for file in os.listdir(pdf_folder) if file.endswith('.pdf')]\n",
    "\n",
    "    documents_csv = []\n",
    "    documents_pdf = []\n",
    "\n",
    "    # Extract text documents and add metadata from CSV files\n",
    "    for csv_file in csv_files:\n",
    "        try:\n",
    "            transcripts_df = pd.read_csv(os.path.join(transcripts_folder, csv_file), delimiter=';')\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: The file {csv_file} was not found.\")\n",
    "            continue\n",
    "\n",
    "        for index, row in transcripts_df.iterrows():\n",
    "            document = Document(\n",
    "                page_content=row[\"transcript_text\"],\n",
    "                metadata={\n",
    "                    \"speaker_name\": row[\"speaker_name\"],\n",
    "                    \"date_time\": row[\"date_time\"],\n",
    "                    \"source\": csv_file\n",
    "                }\n",
    "            )\n",
    "            documents_csv.append(document)\n",
    "\n",
    "    print(\"CSV files loaded...\")\n",
    "\n",
    "    # Load text documents from .pdf files (keeping as they are)\n",
    "    for pdf_file in pdf_files:\n",
    "        loader = PyPDFLoader(os.path.join(pdf_folder, pdf_file))\n",
    "        doc_content = loader.load()\n",
    "        documents_pdf.extend(doc_content)\n",
    "\n",
    "    print(\"PDF files loaded...\")\n",
    "\n",
    "    \n",
    "    # Split text documents into chunks\n",
    "    text_documents = [doc for doc in documents_pdf if isinstance(doc, Document) and doc.page_content]\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0, length_function=len, )\n",
    "    split_docs = text_splitter.split_documents(text_documents)\n",
    "\n",
    "    # Combine split text documents with PDF documents\n",
    "    docs = split_docs + [doc for doc in documents_pdf if not isinstance(doc, Document)]\n",
    "    \n",
    "    # Add data from CSV files to the combined documents\n",
    "    docs.extend(documents_csv)\n",
    "    \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts_folder = os.path.join(\"..\",\"data\", \"reformatted_transcripts\")\n",
    "pdf_folder = os.path.join(\"..\",\"data\", \"EER-site-pages-pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\szh\\Desktop\\EER\\Bot-de-Continuonus\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings()\n",
    "index_name = \"eer-transcripts-pdfs\"\n",
    "pinecone_instance = pc(api_key=os.getenv('PINECONE_API_KEY'), embeddings=embeddings)\n",
    "spec = ServerlessSpec(cloud=\"aws\",region=\"us-east-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files loaded...\n",
      "PDF files loaded...\n"
     ]
    }
   ],
   "source": [
    "docs = datachunk(transcripts_folder, pdf_folder)\n",
    "pinecone_instance.create_index(name=index_name, metric=\"cosine\", dimension=768, spec=spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = Pinecone.from_documents(docs, embeddings, index_name=index_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
